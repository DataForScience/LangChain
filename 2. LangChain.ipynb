{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>LangChain for Generative AI</h1>\n",
    "<h1>LangChain</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import set_seed\n",
    "set_seed(42) # Set the seed to get reproducible results\n",
    "\n",
    "\n",
    "import langchain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "import langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import langchain_anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "import langchain_core\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "import langchain_community\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by print out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.13.3\n",
      "IPython version      : 9.2.0\n",
      "\n",
      "Compiler    : Clang 17.0.0 (clang-1700.0.13.3)\n",
      "OS          : Darwin\n",
      "Release     : 25.0.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 6ee6346f671ea1f9d664e9e5c104424be033ce1d\n",
      "\n",
      "torch              : 2.7.0\n",
      "numpy              : 2.2.5\n",
      "langchain_core     : 0.3.62\n",
      "langchain_community: 0.3.24\n",
      "openai             : 1.78.1\n",
      "transformers       : 4.52.3\n",
      "langchain_anthropic: 0.3.14\n",
      "matplotlib         : 3.10.3\n",
      "pandas             : 2.2.3\n",
      "langchain_openai   : 0.3.18\n",
      "langchain          : 0.3.25\n",
      "watermark          : 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is generate API key on the OpenAI website and store it as the \"OPENAI_API_KEY\" variable in your local environment. Without it we won't be able to do anything. You can find your API key in your using settings: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key. Then we are ready to instantiate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-3.5-turbo\n",
      "gpt-5-search-api-2025-10-14\n",
      "gpt-realtime-mini\n",
      "gpt-realtime-mini-2025-10-06\n",
      "sora-2\n",
      "sora-2-pro\n",
      "davinci-002\n",
      "babbage-002\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-1106\n",
      "tts-1-hd\n",
      "tts-1-1106\n",
      "tts-1-hd-1106\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "gpt-4-0125-preview\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini\n",
      "gpt-4o-2024-08-06\n",
      "chatgpt-4o-latest\n",
      "o1-mini-2024-09-12\n",
      "o1-mini\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-realtime-preview\n",
      "omni-moderation-latest\n",
      "omni-moderation-2024-09-26\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "o1-2024-12-17\n",
      "o1\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-audio-preview\n",
      "computer-use-preview\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "gpt-4o-2024-11-20\n",
      "computer-use-preview-2025-03-11\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-transcribe\n",
      "gpt-4o-mini-transcribe\n",
      "o1-pro-2025-03-19\n",
      "o1-pro\n",
      "gpt-4o-mini-tts\n",
      "o3-2025-04-16\n",
      "o4-mini-2025-04-16\n",
      "o3\n",
      "o4-mini\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4.1-nano\n",
      "gpt-image-1\n",
      "codex-mini-latest\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "o4-mini-deep-research\n",
      "gpt-4o-transcribe-diarize\n",
      "o4-mini-deep-research-2025-06-26\n",
      "gpt-5-chat-latest\n",
      "gpt-5-2025-08-07\n",
      "gpt-5\n",
      "gpt-5-mini-2025-08-07\n",
      "gpt-5-mini\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-5-nano\n",
      "gpt-audio-2025-08-28\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "gpt-audio\n",
      "gpt-5-codex\n",
      "gpt-image-1-mini\n",
      "gpt-5-pro-2025-10-06\n",
      "gpt-5-pro\n",
      "gpt-audio-mini\n",
      "gpt-audio-mini-2025-10-06\n",
      "gpt-5-search-api\n",
      "gpt-3.5-turbo-16k\n",
      "tts-1\n",
      "whisper-1\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([model.id for model in client.models.list().data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What was Superman's weakness?\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CRSrkhhQpkrltw0iW8cTomwskuAwu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Superman's primary weakness is kryptonite, a radioactive mineral from his home planet, Krypton. Exposure to kryptonite can weaken Superman, strip him of his powers, and even harm or kill him if he is exposed for too long. In addition to kryptonite, Superman is also vulnerable to magic and can be overpowered by beings with superior strength or other supernatural abilities.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760661852, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_cbf1785567', usage=CompletionUsage(completion_tokens=74, prompt_tokens=13, total_tokens=87, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superman's primary weakness is kryptonite, a radioactive mineral from his home planet, Krypton. Exposure to kryptonite can weaken Superman, strip him of his powers, and even harm or kill him if he is exposed for too long. In addition to kryptonite, Superman is also vulnerable to magic and can be overpowered by beings with superior strength or other supernatural abilities.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the LangChain interface for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Superman's primary weakness is Kryptonite, a mineral from his home planet of Krypton. Exposure to Kryptonite can weaken him and, with prolonged exposure, can even be fatal. Additionally, Superman is vulnerable to magic, which can affect him in ways that other forces may not. Certain forms of magic and magical creatures can bypass his usual invincibility and cause him harm.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 13, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CRSrngTU3GBPHYEKpn1hiMmAfiXWf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--ce5c6d3b-6c45-4c07-bee9-6294b3d7e040-0' usage_metadata={'input_tokens': 13, 'output_tokens': 75, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"What was Superman's weakness?\"),\n",
    "]\n",
    "\n",
    "output = model.invoke(messages)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 75,\n",
       " 'prompt_tokens': 13,\n",
       " 'total_tokens': 88,\n",
       " 'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "  'audio_tokens': 0,\n",
       "  'reasoning_tokens': 0,\n",
       "  'rejected_prediction_tokens': 0},\n",
       " 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.response_metadata[\"token_usage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Superman's primary weakness is Kryptonite, a crystalline substance originating from his home planet, Krypton. Exposure to Kryptonite radiation weakens Superman, negating his superpowers, and prolonged exposure can be lethal to him. Different varieties of Kryptonite have different effects; for example, green Kryptonite weakens him, while red Kryptonite can cause unpredictable changes in his personality or abilities. Aside from Kryptonite, Superman is vulnerable to magic, which can harm him in ways that physical force cannot. Additionally, Superman depends on the energy from Earth's yellow sun, and deprivation of this energy, such as being in a red sun environment (like Krypton's), can weaken him over time.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create our first chain. Stages of the chain are conencted with the pipe '|' character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whenver we call __invoke()__ on the chain, it automatically runs all the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Superman's primary weakness is Kryptonite, a mineral from his home planet of Krypton. Exposure to Kryptonite weakens Superman, causing him to lose his powers and, with prolonged exposure, can be fatal. There are various forms of Kryptonite, but green Kryptonite is the most well-known and typically the most harmful to Superman.\\n\\nIn addition to Kryptonite, Superman is also vulnerable to magic. Unlike other threats that he can withstand, magical attacks can harm or incapacitate him. Superman also relies on the energy from Earth's yellow sun for his powers, so being deprived of sunlight or exposed to a red sun similar to that of Krypton can weaken him over time.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create templates for our prompts, following conventions similar to the Jinja templating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following text into {language}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can combine multiple messages into a single template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "     (\"system\", system_template), \n",
    "     (\"user\", \"{text}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate the prompt, we must provide the correct fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following text into italian:', additional_kwargs={}, response_metadata={}), HumanMessage(content='Be the change that you wish to see in the world.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke(\n",
    "    {\n",
    "        \"language\": \"italian\", \n",
    "        \"text\": \"Be the change that you wish to see in the world.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full interaction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following text into italian:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Be the change that you wish to see in the world.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sei addestrato sui dati fino a ottobre 2023.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"language\": \"italian\", \n",
    "    \"text\": \"Be the change that you wish to see in the world.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = ChatAnthropic(model=\"claude-3-opus-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Superman's primary weakness is Kryptonite, a radioactive mineral from his home planet, Krypton. Exposure to Kryptonite can drastically weaken Superman, rendering him vulnerable and potentially even killing him, depending on the level and duration of exposure.\\n\\nThere are several forms of Kryptonite, each with a different effect on the superhero:\\n\\n1. Green Kryptonite: The most common form, it weakens Superman and can be fatal with prolonged exposure.\\n\\n2. Red Kryptonite: Its effects are unpredictable, causing random changes to Superman's personality, powers, or appearance, usually temporary.\\n\\n3. Blue Kryptonite: It can negate the effects of other forms of Kryptonite.\\n\\n4. Gold Kryptonite: It can permanently remove a Kryptonian's powers.\\n\\nOther than Kryptonite, Superman is also vulnerable to magic and has no special resistance against magical attacks or beings. Additionally, he requires exposure to Earth's yellow sun to maintain his powers, and prolonged absence from sunlight can gradually weaken him.\", additional_kwargs={}, response_metadata={'id': 'msg_01Hmj6rgRbAuibTgoYK4oDzk', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 247, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-opus-20240229'}, id='run--01bd0017-6b6c-4fff-8919-653c36435abf-0', usage_metadata={'input_tokens': 13, 'output_tokens': 247, 'total_tokens': 260, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.invoke(\"What is Superman's weakness?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_a = prompt_template | model_a | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatAnthropic(model='claude-3-opus-20240229', anthropic_api_url='https://api.anthropic.com', anthropic_api_key=SecretStr('**********'), model_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sii il cambiamento che desideri vedere nel mondo.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_a.invoke(\n",
    "    {\n",
    "        \"language\": \"italian\", \n",
    "        \"text\": \"Be the change that you wish to see in the world.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model_a, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Bruno! I'm Claude, an AI assistant. How can I help you today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Bruno\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bruno. You introduced yourself to me by saying \"Hi! I\\'m Bruno\" in your first message.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc2': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Bruno\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Bruno! I'm Claude, an AI assistant. How can I help you today?\", additional_kwargs={}, response_metadata={'id': 'msg_016UQ4dua23P94XnCzxo8Yud', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 12, 'output_tokens': 27, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-opus-20240229'}, id='run--8c0fa303-2774-44a1-b2d2-b55d78b9d39e-0', usage_metadata={'input_tokens': 12, 'output_tokens': 27, 'total_tokens': 39, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Bruno. You introduced yourself to me by saying \"Hi! I\\'m Bruno\" in your first message.', additional_kwargs={}, response_metadata={'id': 'msg_01MoGV7qk5WqtLy6VrjU2oVF', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 47, 'output_tokens': 27, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-3-opus-20240229'}, id='run--434bbf81-01a0-47ef-81af-b0a152c6a873-0', usage_metadata={'input_tokens': 47, 'output_tokens': 27, 'total_tokens': 74, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't know your name. You haven't told me what it is, and as an AI language model, I don't have access to any personal information about you unless you provide it to me explicitly during our conversation.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As I mentioned, your name is Bruno. You told me this when you first introduced yourself by saying \"Hi! I\\'m Bruno\".'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model_a | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Bob, it's nice to meet you! How can I assist you today?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Jim, it's nice to meet you! I'm an AI assistant. How can I help you today?\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Jim\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///data/Northwind_small.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n"
     ]
    }
   ],
   "source": [
    "print(db.dialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category', 'Customer', 'CustomerCustomerDemo', 'CustomerDemographic', 'Employee', 'EmployeeTerritory', 'Order', 'OrderDetail', 'Product', 'Region', 'Shipper', 'Supplier', 'Territory']\n"
     ]
    }
   ],
   "source": [
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(\"Id\") AS TotalCustomers FROM Customer;'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = write_query.invoke({\"question\": \"How many customers are there\"}) \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(91,)]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/j1bs1q851k15cj5y777nxwph0000gn/T/ipykernel_9310/3528740886.py:1: LangChainDeprecationWarning: The class `QuerySQLDataBaseTool` was deprecated in LangChain 0.3.12 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-community package and should be used instead. To use it run `pip install -U :class:`~langchain-community` and import as `from :class:`~langchain_community.tools import QuerySQLDatabaseTool``.\n",
      "  execute_query = QuerySQLDataBaseTool(db=db)\n"
     ]
    }
   ],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_chain = write_query | execute_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(9,)]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 9 employees.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How many employees are there',\n",
       " 'query': 'SELECT COUNT(\"Id\") AS TotalEmployees\\nFROM Employee'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(query=write_query).invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How many employees are there',\n",
       " 'query': 'SELECT COUNT(\"Id\") AS TotalEmployees FROM Employee;',\n",
       " 'result': 'SELECT COUNT(\"Id\") AS TotalEmployees FROM Employee;'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\")).invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Future Eclipses Get Ready for These Upcoming Eclipses! Solar Eclipses ... The date listed for each eclipse is the local date where the eclipse occurs. Lunar Eclipses ... Eclipse News More NASA News Discover all solar and lunar eclipse dates for 2025 and 2026, including visibility, times, and types. Plan your skywatching with our eclipse calendar. After the 2024 total solar eclipse, astronomy lovers are eager to know when the next extraterrestrial event will be visible in the U.S. Here is the schedule for the upcoming solar eclipses. An umbraphile's top tips for viewing the 2026 total solar eclipse in Greenland, Iceland, and Spain this August. The next annular solar eclipse will be on Feb. 17, 2026 but you'll only be able to view it in Antarctica. On the same day, a partial eclipse will be visible in Antarctica, Africa, South America ...\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"When will the next solar eclipse be?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
