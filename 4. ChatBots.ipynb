{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>LangChain for Generative AI</h1>\n",
    "<h1>ChatBot</h1>\n",
    "        <p>Bruno Gonçalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import langchain\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import GutenbergLoader\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory\n",
    "\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain, ConversationChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by print out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 0b932bf32c4e9b1e4ff9126fc7e8e7ac7b4205ff\n",
      "\n",
      "json            : 2.0.9\n",
      "watermark       : 2.4.3\n",
      "langchain_openai: 0.1.8\n",
      "matplotlib      : 3.8.0\n",
      "langchain       : 0.2.2\n",
      "pandas          : 2.2.3\n",
      "numpy           : 1.26.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"./cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Romeo and Juliet This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: Romeo and Juliet Author: William Shakespeare Release date: November .......'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = GutenbergLoader(\n",
    "    \"https://www.gutenberg.org/cache/epub/1513/pg1513.txt\"\n",
    ")\n",
    "\n",
    "document = loader.load()\n",
    "\n",
    "extrait = ' '.join(document[0].page_content.split()[:100])\n",
    "display(extrait + \" .......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1024, # Each chunk is of size 1024\n",
    "    chunk_overlap=128 # Neigboring chunks overlap by 128 characters\n",
    ") \n",
    "\n",
    "texts = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, \n",
    "    cache_folder=cache_dir\n",
    ")  # Use a pre-cached model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    texts, \n",
    "    embeddings, \n",
    "    persist_directory=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Romeo!\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the document\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo! My cousin Romeo! Romeo!\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "He is wise,\r\n",
      "\n",
      "\n",
      "And on my life hath stol’n him home to bed.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "BENVOLIO.\r\n",
      "\n",
      "\n",
      "He ran this way, and leap’d this orchard wall:\r\n",
      "\n",
      "\n",
      "Call, good Mercutio.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "Nay, I’ll conjure too.\n",
      "====================\n",
      "Romeo! My cousin Romeo! Romeo!\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "He is wise,\r\n",
      "\n",
      "\n",
      "And on my life hath stol’n him home to bed.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "BENVOLIO.\r\n",
      "\n",
      "\n",
      "He ran this way, and leap’d this orchard wall:\r\n",
      "\n",
      "\n",
      "Call, good Mercutio.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "Nay, I’ll conjure too.\n"
     ]
    }
   ],
   "source": [
    "# Check the content of the first document\n",
    "print(docs[0].page_content)\n",
    "print(\"=\"*20)\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a wrapper around the functionality of our vector database so we can search for similar documents in the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Use the following pieces of context to answer the question at the end. If '\n",
      " \"you don't know the answer, just say that you don't know, don't try to make \"\n",
      " 'up an answer. Use three sentences maximum. Keep the answer as concise as '\n",
      " 'possible. Always say \"thanks for asking!\" at the end of the answer. \\n'\n",
      " '\\n'\n",
      " '{context}\\n'\n",
      " '\\n'\n",
      " 'Question: {question}\\n'\n",
      " '\\n'\n",
      " 'Helpful Answer:')\n"
     ]
    }
   ],
   "source": [
    "pprint(QA_CHAIN_PROMPT.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Juliet's family is the Capulet family. Thanks for asking!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Juliets family?\"\n",
    "\n",
    "query_results_venice = qa.invoke(query)\n",
    "print(\"#\" * 12)\n",
    "query_results_venice['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Romeo and Juliet both die, leading to a reconciliation between their feuding families, the Capulets and the Montagues. Thanks for asking!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What happens to Romeo and Juliet?\"\n",
    "query_results_romeo = qa.invoke(query)\n",
    "print(\"#\" * 12)\n",
    "query_results_romeo['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mercutio is a character in William Shakespeare\\'s play \"Romeo and Juliet.\" He is a close friend of Romeo and is known for his witty and playful nature. Thanks for asking!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is Mercutio?\"\n",
    "query_results_romeo = qa.invoke(query)\n",
    "print(\"#\" * 12)\n",
    "query_results_romeo['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems you are quoting from a scene in \"Romeo and Juliet\" where Benvolio and Mercutio are looking for Romeo after he has leapt over the orchard wall. They believe he has gone home to bed, but he is actually hiding nearby. Thanks for asking!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Does Romeo live?\"\n",
    "qa_chain_docs = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       # Return source documents\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain_docs({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo! My cousin Romeo! Romeo!\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "He is wise,\r\n",
      "\n",
      "\n",
      "And on my life hath stol’n him home to bed.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "BENVOLIO.\r\n",
      "\n",
      "\n",
      "He ran this way, and leap’d this orchard wall:\r\n",
      "\n",
      "\n",
      "Call, good Mercutio.\r\n",
      "\n",
      "\n",
      "\r\n",
      "\n",
      "\n",
      "MERCUTIO.\r\n",
      "\n",
      "\n",
      "Nay, I’ll conjure too.\n"
     ]
    }
   ],
   "source": [
    "print(result['source_documents'][2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
